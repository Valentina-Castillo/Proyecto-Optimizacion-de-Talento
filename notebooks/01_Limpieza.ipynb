{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf1c995",
   "metadata": {},
   "source": [
    "## **LIMPIEZA Y TRANSFORMACI√ìN DE LOS DATOS**\n",
    "\n",
    "Este notebook realiza el proceso completo de limpieza y preparaci√≥n de datos de recursos humanos.\n",
    "\n",
    "**Pasos principales:**\n",
    "1. Importaci√≥n de librer√≠as necesarias\n",
    "2. Carga de datos originales\n",
    "3. Normalizaci√≥n de nombres de columnas\n",
    "4. Limpieza de duplicados y columnas sin valor\n",
    "5. Normalizaci√≥n de datos categ√≥ricos\n",
    "6. Conversi√≥n de tipos de datos\n",
    "7. Mapeo de variables ordinales\n",
    "8. Imputaci√≥n de valores nulos\n",
    "9. Exportaci√≥n de datos limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72a1501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INSTALACI√ìN E IMPORTACI√ìN DE LIBRER√çAS\n",
    "# ============================================================================\n",
    "\n",
    "# Librer√≠as para manipulaci√≥n de datos\n",
    "import pandas as pd  # Trabajo con DataFrames y an√°lisis de datos\n",
    "import numpy as np   # Operaciones num√©ricas y arrays\n",
    "import re            # Expresiones regulares para procesamiento de texto\n",
    "\n",
    "# Librer√≠as de scikit-learn para imputaci√≥n y escalado\n",
    "from sklearn.impute import SimpleImputer, KNNImputer  # M√©todos de imputaci√≥n de nulos\n",
    "from sklearn.preprocessing import StandardScaler      # Estandarizaci√≥n de variables num√©ricas\n",
    "\n",
    "# Librer√≠a del sistema operativo\n",
    "import os  # Gesti√≥n de rutas y archivos del sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "192618a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURACI√ìN DE VISUALIZACI√ìN DE PANDAS\n",
    "# ============================================================================\n",
    "\n",
    "# Mostrar todas las columnas al visualizar DataFrames (sin truncar)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Mostrar hasta 100 filas (por defecto son 60)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35c894fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobRole</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>MonthlyRate</th>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <th>Over18</th>\n",
       "      <th>OverTime</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>sALES eXECUTIVE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>5993.0</td>\n",
       "      <td>19479</td>\n",
       "      <td>8</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>rESEARCH sCIENTIST</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>5130.0</td>\n",
       "      <td>24907</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>No</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>lABORATORY tECHNICIAN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>2396</td>\n",
       "      <td>6</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0  41.0       Yes      Travel_Rarely       1102                   Sales   \n",
       "1  49.0        No  Travel_Frequently        279  Research & Development   \n",
       "2  37.0       Yes      Travel_Rarely       1373  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "\n",
       "   EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  JobLevel  \\\n",
       "0                        2  Female          94               3         2   \n",
       "1                        3    Male          61               2         2   \n",
       "2                        4    Male          92               2         1   \n",
       "\n",
       "                   JobRole  JobSatisfaction MaritalStatus  MonthlyIncome  \\\n",
       "0         sALES eXECUTIVE               4.0        Single         5993.0   \n",
       "1      rESEARCH sCIENTIST               2.0       Married         5130.0   \n",
       "2   lABORATORY tECHNICIAN               3.0        Single         2090.0   \n",
       "\n",
       "   MonthlyRate  NumCompaniesWorked Over18 OverTime  PercentSalaryHike  \\\n",
       "0        19479                   8      Y      Yes                 11   \n",
       "1        24907                   1      Y       No                 23   \n",
       "2         2396                   6      Y      Yes                 15   \n",
       "\n",
       "   PerformanceRating  RelationshipSatisfaction  StandardHours  \\\n",
       "0                  3                         1           80.0   \n",
       "1                  4                         4            NaN   \n",
       "2                  3                         2            NaN   \n",
       "\n",
       "   StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n",
       "0                 0                  8                    0.0   \n",
       "1                 1                 10                    3.0   \n",
       "2                 0                  7                    3.0   \n",
       "\n",
       "   WorkLifeBalance  YearsAtCompany  YearsInCurrentRole  \\\n",
       "0                1               6                   4   \n",
       "1                3              10                   7   \n",
       "2                3               0                   0   \n",
       "\n",
       "   YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                        0                   5.0  \n",
       "1                        1                   7.0  \n",
       "2                        0                   0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CARGA DE DATOS ORIGINALES\n",
    "# ============================================================================\n",
    "\n",
    "# Leer el archivo CSV con los datos de recursos humanos desde la carpeta raw\n",
    "df = pd.read_csv('../data/raw/hr.csv')\n",
    "\n",
    "# Mostrar las primeras 3 filas para verificar la carga correcta\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f16b97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1474 entries, 0 to 1473\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       1401 non-null   float64\n",
      " 1   Attrition                 1474 non-null   object \n",
      " 2   BusinessTravel            1357 non-null   object \n",
      " 3   DailyRate                 1474 non-null   int64  \n",
      " 4   Department                1445 non-null   object \n",
      " 5   DistanceFromHome          1474 non-null   int64  \n",
      " 6   Education                 1474 non-null   int64  \n",
      " 7   EducationField            1416 non-null   object \n",
      " 8   EmployeeCount             1474 non-null   int64  \n",
      " 9   EmployeeNumber            1474 non-null   int64  \n",
      " 10  EnvironmentSatisfaction   1474 non-null   int64  \n",
      " 11  Gender                    1474 non-null   object \n",
      " 12  HourlyRate                1474 non-null   int64  \n",
      " 13  JobInvolvement            1474 non-null   int64  \n",
      " 14  JobLevel                  1474 non-null   int64  \n",
      " 15  JobRole                   1474 non-null   object \n",
      " 16  JobSatisfaction           1445 non-null   float64\n",
      " 17  MaritalStatus             1342 non-null   object \n",
      " 18  MonthlyIncome             1460 non-null   float64\n",
      " 19  MonthlyRate               1474 non-null   int64  \n",
      " 20  NumCompaniesWorked        1474 non-null   int64  \n",
      " 21  Over18                    1474 non-null   object \n",
      " 22  OverTime                  1430 non-null   object \n",
      " 23  PercentSalaryHike         1474 non-null   int64  \n",
      " 24  PerformanceRating         1474 non-null   int64  \n",
      " 25  RelationshipSatisfaction  1474 non-null   int64  \n",
      " 26  StandardHours             1310 non-null   float64\n",
      " 27  StockOptionLevel          1474 non-null   int64  \n",
      " 28  TotalWorkingYears         1474 non-null   int64  \n",
      " 29  TrainingTimesLastYear     1386 non-null   float64\n",
      " 30  WorkLifeBalance           1474 non-null   int64  \n",
      " 31  YearsAtCompany            1474 non-null   int64  \n",
      " 32  YearsInCurrentRole        1474 non-null   int64  \n",
      " 33  YearsSinceLastPromotion   1474 non-null   int64  \n",
      " 34  YearsWithCurrManager      1326 non-null   float64\n",
      "dtypes: float64(6), int64(20), object(9)\n",
      "memory usage: 403.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normalizacion_columnas",
   "metadata": {},
   "source": [
    "---\n",
    "## **1. NORMALIZACI√ìN DE NOMBRES DE COLUMNAS**\n",
    "\n",
    "Transformamos los nombres de las columnas a un formato est√°ndar (snake_case) para:\n",
    "- Facilitar el acceso a las columnas sin errores de may√∫sculas\n",
    "- Mejorar la legibilidad del c√≥digo\n",
    "- Seguir las mejores pr√°cticas de nomenclatura en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0e0cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_nombres_columnas(lista_columnas, mostrar_resumen=True):\n",
    "    \"\"\"\n",
    "    Normaliza los nombres de las columnas de un DataFrame a formato snake_case.\n",
    "    \n",
    "    El proceso de normalizaci√≥n incluye:\n",
    "    - Eliminar espacios al inicio y al final\n",
    "    - Eliminar caracteres especiales (excepto guiones bajos)\n",
    "    - Convertir de CamelCase o PascalCase a snake_case\n",
    "    - Convertir todo a min√∫sculas\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    lista_columnas : list\n",
    "        Lista con los nombres originales de las columnas\n",
    "    mostrar_resumen : bool, default=True\n",
    "        Si True, imprime un resumen de los cambios realizados\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    list\n",
    "        Lista de nombres de columnas normalizados en formato snake_case\n",
    "        \n",
    "    Ejemplo:\n",
    "    --------\n",
    "    >>> normalizar_nombres_columnas(['EmployeeNumber', 'BusinessTravel'])\n",
    "    ['employee_number', 'business_travel']\n",
    "    \"\"\"\n",
    "    nombres_normalizados = []\n",
    "    \n",
    "    for nombre in lista_columnas:\n",
    "        # Paso 1: Eliminar espacios al inicio y al final\n",
    "        limpia = nombre.strip()\n",
    "        \n",
    "        # Paso 2: Eliminar caracteres especiales, conservando solo letras, n√∫meros y guiones bajos\n",
    "        limpia = re.sub(r'[^0-9a-zA-Z_]', '', limpia)\n",
    "        \n",
    "        # Paso 3: Insertar gui√≥n bajo entre min√∫scula/n√∫mero y may√∫scula\n",
    "        # Ejemplo: 'BusinessTravel' -> 'Business_Travel'\n",
    "        limpia = re.sub(r'([a-z0-9])([A-Z])', r'\\1_\\2', limpia)\n",
    "        \n",
    "        # Paso 4: Convertir todo a min√∫sculas\n",
    "        nombres_normalizados.append(limpia.lower())\n",
    "\n",
    "    # Mostrar resumen de cambios si se solicita\n",
    "    if mostrar_resumen:\n",
    "        print(\"Normalizaci√≥n de nombres de columnas finalizada.\")\n",
    "        print(f\"Total columnas procesadas: {len(nombres_normalizados)}\")\n",
    "        print(\"Resumen de cambios:\")\n",
    "        for orig, nuevo in zip(lista_columnas, nombres_normalizados):\n",
    "            print(f\"'{orig}' -> '{nuevo}'\")\n",
    "    \n",
    "    return nombres_normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "897cb4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizaci√≥n de nombres de columnas finalizada.\n",
      "Total columnas procesadas: 35\n",
      "Resumen de cambios:\n",
      "'Age' -> 'age'\n",
      "'Attrition' -> 'attrition'\n",
      "'BusinessTravel' -> 'business_travel'\n",
      "'DailyRate' -> 'daily_rate'\n",
      "'Department' -> 'department'\n",
      "'DistanceFromHome' -> 'distance_from_home'\n",
      "'Education' -> 'education'\n",
      "'EducationField' -> 'education_field'\n",
      "'EmployeeCount' -> 'employee_count'\n",
      "'EmployeeNumber' -> 'employee_number'\n",
      "'EnvironmentSatisfaction' -> 'environment_satisfaction'\n",
      "'Gender' -> 'gender'\n",
      "'HourlyRate' -> 'hourly_rate'\n",
      "'JobInvolvement' -> 'job_involvement'\n",
      "'JobLevel' -> 'job_level'\n",
      "'JobRole' -> 'job_role'\n",
      "'JobSatisfaction' -> 'job_satisfaction'\n",
      "'MaritalStatus' -> 'marital_status'\n",
      "'MonthlyIncome' -> 'monthly_income'\n",
      "'MonthlyRate' -> 'monthly_rate'\n",
      "'NumCompaniesWorked' -> 'num_companies_worked'\n",
      "'Over18' -> 'over18'\n",
      "'OverTime' -> 'over_time'\n",
      "'PercentSalaryHike' -> 'percent_salary_hike'\n",
      "'PerformanceRating' -> 'performance_rating'\n",
      "'RelationshipSatisfaction' -> 'relationship_satisfaction'\n",
      "'StandardHours' -> 'standard_hours'\n",
      "'StockOptionLevel' -> 'stock_option_level'\n",
      "'TotalWorkingYears' -> 'total_working_years'\n",
      "'TrainingTimesLastYear' -> 'training_times_last_year'\n",
      "'WorkLifeBalance' -> 'work_life_balance'\n",
      "'YearsAtCompany' -> 'years_at_company'\n",
      "'YearsInCurrentRole' -> 'years_in_current_role'\n",
      "'YearsSinceLastPromotion' -> 'years_since_last_promotion'\n",
      "'YearsWithCurrManager' -> 'years_with_curr_manager'\n"
     ]
    }
   ],
   "source": [
    "# Aplicar la normalizaci√≥n de nombres a todas las columnas del DataFrame\n",
    "df.columns = normalizar_nombres_columnas(df.columns.tolist(), mostrar_resumen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "establecer_indice",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. ESTABLECER COLUMNA IDENTIFICADORA COMO √çNDICE**\n",
    "\n",
    "Usamos la columna de n√∫mero de empleado como √≠ndice del DataFrame para:\n",
    "- Facilitar el acceso a registros individuales\n",
    "- Mejorar la eficiencia en b√∫squedas\n",
    "- Dar estructura l√≥gica al dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b27a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usar_columna_como_indice(df, columna_original='employee_number', indice='id'):\n",
    "    \"\"\"\n",
    "    Establece una columna del DataFrame como √≠ndice y la renombra.\n",
    "    \n",
    "    Esta funci√≥n es √∫til para identificar de forma √∫nica cada registro\n",
    "    y facilitar el acceso a los datos.\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame a modificar\n",
    "    columna_original : str, default='employee_number'\n",
    "        Nombre de la columna que se usar√° como √≠ndice\n",
    "    indice : str, default='id'\n",
    "        Nuevo nombre para el √≠ndice (normalmente 'id')\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame con la columna establecida como √≠ndice y renombrada\n",
    "        \n",
    "    Raises:\n",
    "    -------\n",
    "    ValueError\n",
    "        Si la columna especificada no existe en el DataFrame\n",
    "    \"\"\"\n",
    "    # Crear copia para no modificar el DataFrame original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Verificar que la columna existe antes de intentar usarla\n",
    "    if columna_original not in df.columns:\n",
    "        raise ValueError(f\"La columna '{columna_original}' no existe en el DataFrame.\")\n",
    "    \n",
    "    # Renombrar la columna al nombre corto deseado\n",
    "    df.rename(columns={columna_original: indice}, inplace=True)\n",
    "    \n",
    "    # Establecer la columna renombrada como √≠ndice del DataFrame\n",
    "    df.set_index(indice, inplace=True)\n",
    "    \n",
    "    print(f\"Columna '{columna_original}' renombrada a '{indice}' y establecida como √≠ndice correctamente.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b72d0474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna 'employee_number' renombrada a 'id' y establecida como √≠ndice correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Establecer employee_number como √≠ndice y renombrarlo a 'id'\n",
    "df = usar_columna_como_indice(df, columna_original='employee_number', indice='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eliminar_duplicados",
   "metadata": {},
   "source": [
    "---\n",
    "## **3. ELIMINACI√ìN DE FILAS DUPLICADAS**\n",
    "\n",
    "Identificamos y eliminamos registros duplicados para:\n",
    "- Evitar sesgos en el an√°lisis\n",
    "- Mantener la integridad de los datos\n",
    "- Mejorar la calidad del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5edba930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_filas_duplicadas(df, keep='first'):\n",
    "    \"\"\"\n",
    "    Elimina filas duplicadas del DataFrame.\n",
    "    \n",
    "    Los duplicados son filas que tienen valores id√©nticos en todas las columnas.\n",
    "    Esta funci√≥n permite controlar qu√© ocurrencia del duplicado se conserva.\n",
    "\n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame a procesar\n",
    "    keep : {'first', 'last', False}, default='first'\n",
    "        Determina qu√© duplicados conservar:\n",
    "        - 'first'  : conserva la primera aparici√≥n de cada duplicado\n",
    "        - 'last'   : conserva la √∫ltima aparici√≥n de cada duplicado\n",
    "        - False    : elimina todas las filas duplicadas (ninguna se conserva)\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame sin filas duplicadas\n",
    "    \"\"\"\n",
    "    # Crear copia para no modificar el DataFrame original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Guardar el n√∫mero de filas antes de la limpieza\n",
    "    num_filas_antes_limpieza = df.shape[0]\n",
    "\n",
    "    # Eliminar filas duplicadas seg√∫n el criterio especificado\n",
    "    df.drop_duplicates(keep=keep, inplace=True)\n",
    "\n",
    "    # Calcular cu√°ntas filas fueron eliminadas\n",
    "    filas_eliminadas = num_filas_antes_limpieza - df.shape[0]\n",
    "\n",
    "    # Mostrar resumen del proceso\n",
    "    print(f\"Filas antes de eliminar duplicados: {num_filas_antes_limpieza}\")\n",
    "    print(f\"Filas eliminadas por duplicados: {filas_eliminadas}\")\n",
    "    print(f\"Filas en el DataFrame tras el procesamiento: {df.shape[0]}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "568960c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas antes de eliminar duplicados: 1474\n",
      "Filas eliminadas por duplicados: 4\n",
      "Filas en el DataFrame tras el procesamiento: 1470\n"
     ]
    }
   ],
   "source": [
    "# Eliminar duplicados conservando la primera aparici√≥n de cada registro\n",
    "df = eliminar_filas_duplicadas(df, keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eliminar_columnas_sin_valor",
   "metadata": {},
   "source": [
    "---\n",
    "## **4. ELIMINACI√ìN DE COLUMNAS SIN APORTE ANAL√çTICO**\n",
    "\n",
    "Eliminamos columnas que no aportan informaci√≥n √∫til:\n",
    "- **Columnas constantes**: todas las filas tienen el mismo valor\n",
    "- **Columnas con alta cardinalidad**: casi todos los valores son √∫nicos\n",
    "\n",
    "Esto reduce dimensionalidad y mejora la eficiencia del an√°lisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb35f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_columnas_sin_aporte_analitico(df, umbral_cardinalidad=0.95):\n",
    "    \"\"\"\n",
    "    Elimina columnas del DataFrame que no aportan valor anal√≠tico.\n",
    "    \n",
    "    Se consideran sin aporte anal√≠tico:\n",
    "    - Columnas constantes: todos los valores son iguales (no aportan variabilidad)\n",
    "    - Columnas con alta cardinalidad: la proporci√≥n de valores √∫nicos es muy alta\n",
    "\n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame a limpiar\n",
    "    umbral_cardinalidad : float, default=0.95\n",
    "        Proporci√≥n m√°xima de valores √∫nicos permitida (entre 0 y 1)\n",
    "        Si la cardinalidad supera este umbral, la columna se elimina\n",
    "        Por defecto 0.95 significa que si m√°s del 95% de valores son √∫nicos, se elimina\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame con las columnas problem√°ticas eliminadas\n",
    "    \"\"\"\n",
    "    # Crear copia para no modificar el DataFrame original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Lista para almacenar nombres de columnas a eliminar\n",
    "    columnas_a_eliminar = []\n",
    "\n",
    "    # Revisar cada columna del DataFrame\n",
    "    for columna in df.columns:\n",
    "        # Caso 1: Columna constante (todos los valores son iguales)\n",
    "        # nunique() cuenta cu√°ntos valores √∫nicos hay\n",
    "        if df[columna].nunique() == 1:\n",
    "            columnas_a_eliminar.append(columna)\n",
    "            \n",
    "        # Caso 2: Columna con alta cardinalidad\n",
    "        # Calculamos la proporci√≥n de valores √∫nicos respecto al total de filas\n",
    "        elif df[columna].nunique() / len(df) > umbral_cardinalidad:\n",
    "            columnas_a_eliminar.append(columna)\n",
    "\n",
    "    # Eliminar todas las columnas identificadas\n",
    "    df.drop(columns=columnas_a_eliminar, inplace=True)\n",
    "\n",
    "    # Mostrar resumen de la operaci√≥n\n",
    "    print(f\"Columnas eliminadas por no aportar valor anal√≠tico: {columnas_a_eliminar}\")\n",
    "    print(f\"Total columnas eliminadas: {len(columnas_a_eliminar)}\")\n",
    "    print(f\"Columnas restantes en el DataFrame: {df.shape[1]}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6936ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas eliminadas por no aportar valor anal√≠tico: ['employee_count', 'monthly_rate', 'over18', 'standard_hours']\n",
      "Total columnas eliminadas: 4\n",
      "Columnas restantes en el DataFrame: 30\n"
     ]
    }
   ],
   "source": [
    "# Eliminar columnas constantes y con alta cardinalidad (>95% valores √∫nicos)\n",
    "df = eliminar_columnas_sin_aporte_analitico(df, umbral_cardinalidad=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normalizar_texto",
   "metadata": {},
   "source": [
    "---\n",
    "## **5. NORMALIZACI√ìN DE COLUMNAS DE TEXTO**\n",
    "\n",
    "Estandarizamos los valores de texto para:\n",
    "- Eliminar espacios innecesarios\n",
    "- Unificar formato (Title Case)\n",
    "- Corregir errores tipogr√°ficos\n",
    "- Simplificar categor√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6468f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_columnas_texto(df, mapeos_reemplazo=None, mostrar_resumen=True):\n",
    "    \"\"\"\n",
    "    Normaliza columnas de texto o categ√≥ricas y aplica correcciones espec√≠ficas.\n",
    "    \n",
    "    El proceso incluye:\n",
    "    1. Eliminar espacios en blanco al inicio y al final de cada valor\n",
    "    2. Convertir texto a Title Case (Primera Letra May√∫scula)\n",
    "    3. Aplicar mapeos de reemplazo personalizados (correcciones, simplificaciones)\n",
    "\n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame a procesar\n",
    "    mapeos_reemplazo : dict, optional\n",
    "        Diccionario de mapeos para corregir valores espec√≠ficos\n",
    "        Formato: {'nombre_columna': {'valor_antiguo': 'valor_nuevo', ...}, ...}\n",
    "        Ejemplo: {'marital_status': {'Marreid': 'Married'}}\n",
    "    mostrar_resumen : bool, default=True\n",
    "        Si True, imprime resumen de columnas procesadas y categor√≠as finales\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame con columnas de texto normalizadas\n",
    "    \"\"\"\n",
    "    # Crear copia para no modificar el DataFrame original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Identificar columnas de texto/categ√≥ricas\n",
    "    columnas_texto = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Lista para rastrear columnas donde se aplicaron reemplazos\n",
    "    columnas_con_reemplazo = []\n",
    "\n",
    "    for col in columnas_texto:\n",
    "        # Paso 1: Eliminar espacios al inicio/final y convertir a Title Case\n",
    "        # .str.strip() elimina espacios en blanco\n",
    "        # .str.title() convierte a formato \"Primera Letra May√∫scula\"\n",
    "        df[col] = df[col].str.strip().str.title()\n",
    "\n",
    "        # Paso 2: Aplicar mapeos de reemplazo espec√≠ficos si existen\n",
    "        if mapeos_reemplazo and col in mapeos_reemplazo:\n",
    "            df[col] = df[col].replace(mapeos_reemplazo[col])\n",
    "            columnas_con_reemplazo.append(col)\n",
    "\n",
    "    # Mostrar resumen del proceso\n",
    "    if mostrar_resumen:\n",
    "        print(\"Normalizaci√≥n de columnas de texto finalizada.\")\n",
    "        print(f\"Columnas procesadas: {columnas_texto}\")\n",
    "\n",
    "        if columnas_con_reemplazo:\n",
    "            print(f\"Se aplicaron mapeos de reemplazo en: {columnas_con_reemplazo}\")\n",
    "            for col in columnas_con_reemplazo:\n",
    "                print(f\"Categor√≠as finales de '{col}': {df[col].unique().tolist()}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fccee631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizaci√≥n de columnas de texto finalizada.\n",
      "Columnas procesadas: ['attrition', 'business_travel', 'department', 'education_field', 'gender', 'job_role', 'marital_status', 'over_time']\n",
      "Se aplicaron mapeos de reemplazo en: ['business_travel', 'marital_status']\n",
      "Categor√≠as finales de 'business_travel': ['Rarely', 'Frequently', 'Non', nan]\n",
      "Categor√≠as finales de 'marital_status': ['Single', 'Married', 'Divorced', nan]\n"
     ]
    }
   ],
   "source": [
    "# Definir mapeos para corregir errores tipogr√°ficos y simplificar valores\n",
    "mapeos_reemplazo = {\n",
    "    # Corregir error tipogr√°fico en estado civil\n",
    "    'marital_status': {'Marreid': 'Married'},\n",
    "    \n",
    "    # Simplificar categor√≠as de frecuencia de viaje\n",
    "    'business_travel': {\n",
    "        'Travel_Rarely': 'Rarely',\n",
    "        'Travel_Frequently': 'Frequently',\n",
    "        'Non-Travel': 'Non'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Aplicar normalizaci√≥n de texto con los mapeos definidos\n",
    "df = normalizar_columnas_texto(df, mapeos_reemplazo=mapeos_reemplazo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a2556",
   "metadata": {},
   "source": [
    "---\n",
    "## **6. CONVERSI√ìN DE TIPOS DE DATOS**\n",
    "\n",
    "Convertimos columnas a los tipos de datos apropiados para:\n",
    "- Reducir consumo de memoria\n",
    "- Permitir operaciones matem√°ticas correctas\n",
    "- Manejar valores nulos de forma adecuada (Int64 vs int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45c19055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_tipos_columnas(df, mapeo_tipos, mostrar_resumen=True):\n",
    "    \"\"\"\n",
    "    Convierte columnas de un DataFrame a tipos de datos espec√≠ficos.\n",
    "    \n",
    "    Esta funci√≥n es √∫til para optimizar el uso de memoria y asegurar\n",
    "    que cada columna tenga el tipo de dato correcto para su an√°lisis.\n",
    "\n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame a modificar\n",
    "    mapeo_tipos : dict\n",
    "        Diccionario con nombres de columnas como claves y tipos de datos como valores\n",
    "        Tipos comunes: int, float, 'Int64', 'Float64', 'category', 'str'\n",
    "        Nota: 'Int64' (may√∫scula) permite valores nulos, 'int64' (min√∫scula) no\n",
    "        Ejemplo: {'age': 'Int64', 'salary': float}\n",
    "    mostrar_resumen : bool, default=True\n",
    "        Si True, imprime resumen de conversiones y tabla de tipos finales\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame con columnas convertidas a los tipos especificados\n",
    "    \"\"\"\n",
    "    # Crear copia para no modificar el DataFrame original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Lista para rastrear columnas convertidas exitosamente\n",
    "    columnas_convertidas = []\n",
    "\n",
    "    # Intentar convertir cada columna especificada\n",
    "    for columna, tipo in mapeo_tipos.items():\n",
    "        # Verificar que la columna existe en el DataFrame\n",
    "        if columna in df.columns:\n",
    "            try:\n",
    "                # Intentar la conversi√≥n de tipo\n",
    "                # errors='ignore' evita errores si la conversi√≥n falla en algunos valores\n",
    "                df[columna] = df[columna].astype(tipo, errors='ignore')\n",
    "                columnas_convertidas.append(columna)\n",
    "            except Exception as e:\n",
    "                # Si falla, informar del error pero continuar con otras columnas\n",
    "                print(f\"No se pudo convertir la columna '{columna}' a {tipo}: {e}\")\n",
    "\n",
    "    # Mostrar resumen del proceso\n",
    "    if mostrar_resumen:\n",
    "        print(\"Conversi√≥n de tipos finalizada.\")\n",
    "        if columnas_convertidas:\n",
    "            print(f\"Columnas convertidas: {columnas_convertidas}\")\n",
    "        else:\n",
    "            print(\"No se convirti√≥ ninguna columna.\")\n",
    "\n",
    "        # Mostrar tabla con todos los tipos de datos finales\n",
    "        print(\"\\nTipos de datos finales por columna:\")\n",
    "        tipos_finales = pd.DataFrame({\n",
    "            \"Columna\": df.columns,\n",
    "            \"Tipo de dato\": [df[col].dtype for col in df.columns]\n",
    "        })\n",
    "        display(tipos_finales)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da27e793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversi√≥n de tipos finalizada.\n",
      "Columnas convertidas: ['age', 'daily_rate', 'hourly_rate', 'training_times_last_year', 'years_with_curr_manager']\n",
      "\n",
      "Tipos de datos finales por columna:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columna</th>\n",
       "      <th>Tipo de dato</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attrition</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business_travel</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daily_rate</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>department</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>distance_from_home</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>education</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>education_field</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>environment_satisfaction</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gender</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hourly_rate</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>job_involvement</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>job_level</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>job_role</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>job_satisfaction</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>marital_status</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>monthly_income</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num_companies_worked</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>over_time</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>percent_salary_hike</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>performance_rating</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>relationship_satisfaction</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>stock_option_level</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>total_working_years</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>training_times_last_year</td>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>work_life_balance</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>years_at_company</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>years_in_current_role</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>years_since_last_promotion</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>years_with_curr_manager</td>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Columna Tipo de dato\n",
       "0                          age        Int64\n",
       "1                    attrition       object\n",
       "2              business_travel       object\n",
       "3                   daily_rate      float64\n",
       "4                   department       object\n",
       "5           distance_from_home        int64\n",
       "6                    education        int64\n",
       "7              education_field       object\n",
       "8     environment_satisfaction        int64\n",
       "9                       gender       object\n",
       "10                 hourly_rate      float64\n",
       "11             job_involvement        int64\n",
       "12                   job_level        int64\n",
       "13                    job_role       object\n",
       "14            job_satisfaction      float64\n",
       "15              marital_status       object\n",
       "16              monthly_income      float64\n",
       "17        num_companies_worked        int64\n",
       "18                   over_time       object\n",
       "19         percent_salary_hike        int64\n",
       "20          performance_rating        int64\n",
       "21   relationship_satisfaction        int64\n",
       "22          stock_option_level        int64\n",
       "23         total_working_years        int64\n",
       "24    training_times_last_year        Int64\n",
       "25           work_life_balance        int64\n",
       "26            years_at_company        int64\n",
       "27       years_in_current_role        int64\n",
       "28  years_since_last_promotion        int64\n",
       "29     years_with_curr_manager        Int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir el mapeo de tipos de datos para cada columna\n",
    "mapeo_tipos = {\n",
    "    \"age\": \"Int64\",                      # Int64 permite valores nulos (nullable integer)\n",
    "    \"daily_rate\": float,                 # Tasa diaria como n√∫mero decimal\n",
    "    \"hourly_rate\": float,                # Tasa horaria como n√∫mero decimal\n",
    "    \"training_times_last_year\": \"Int64\", # N√∫mero de entrenamientos (puede tener nulos)\n",
    "    \"years_with_curr_manager\": \"Int64\",  # A√±os con el manager actual (puede tener nulos)\n",
    "}\n",
    "\n",
    "# Aplicar la conversi√≥n de tipos\n",
    "df = convertir_tipos_columnas(df, mapeo_tipos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mapear_ordinales",
   "metadata": {},
   "source": [
    "---\n",
    "## **7. MAPEO DE VARIABLES ORDINALES**\n",
    "\n",
    "Convertimos valores num√©ricos codificados en etiquetas sem√°nticas para:\n",
    "- Mejorar la interpretabilidad (1‚Üí\"Becario\" es m√°s claro que 1)\n",
    "- Facilitar la comunicaci√≥n de resultados\n",
    "- Mantener el orden l√≥gico de las categor√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "041fac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapear_columnas_ordinales(df, mapeos_columnas, mostrar_resumen=True):\n",
    "    \"\"\"\n",
    "    Aplica mapeo sem√°ntico a columnas ordinales del DataFrame.\n",
    "    \n",
    "    Las variables ordinales son aquellas que tienen un orden natural\n",
    "    (ej: 1=Bajo, 2=Medio, 3=Alto). Esta funci√≥n las convierte de c√≥digos\n",
    "    num√©ricos a etiquetas textuales m√°s comprensibles.\n",
    "\n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame a modificar\n",
    "    mapeos_columnas : dict\n",
    "        Diccionario con nombres de columnas como claves y diccionarios de mapeo como valores\n",
    "        Formato: {'columna': {valor_numerico: 'etiqueta_texto', ...}, ...}\n",
    "        Ejemplo:\n",
    "        {\n",
    "            \"education\": {1: \"Sin estudios\", 2: \"Educaci√≥n b√°sica\", ...},\n",
    "            \"job_level\": {1: \"Becario\", 2: \"Junior\", ...}\n",
    "        }\n",
    "    mostrar_resumen : bool, default=True\n",
    "        Si True, imprime resumen de columnas mapeadas y sus valores √∫nicos\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame con columnas ordinales mapeadas a etiquetas textuales\n",
    "    \"\"\"\n",
    "    # Crear copia para no modificar el DataFrame original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Lista para rastrear columnas mapeadas\n",
    "    columnas_mapeadas = []\n",
    "\n",
    "    # Aplicar cada mapeo especificado\n",
    "    for columna, mapa in mapeos_columnas.items():\n",
    "        # Verificar que la columna existe\n",
    "        if columna in df.columns:\n",
    "            # .map() reemplaza cada valor seg√∫n el diccionario proporcionado\n",
    "            # Ej: si mapa = {1: \"Bajo\", 2: \"Alto\"}, entonces 1 se convierte en \"Bajo\"\n",
    "            df[columna] = df[columna].map(mapa)\n",
    "            columnas_mapeadas.append(columna)\n",
    "\n",
    "    # Mostrar resumen del proceso\n",
    "    if mostrar_resumen:\n",
    "        print(\"üîπ Mapeo de columnas ordinales finalizado.\")\n",
    "        print(f\"Columnas mapeadas: {columnas_mapeadas}\")\n",
    "        # Mostrar valores √∫nicos de cada columna mapeada para verificaci√≥n\n",
    "        for col in columnas_mapeadas:\n",
    "            print(f\"{col}: {df[col].unique()}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4aaa671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Mapeo de columnas ordinales finalizado.\n",
      "Columnas mapeadas: ['job_involvement', 'job_satisfaction', 'work_life_balance', 'education', 'job_level']\n",
      "job_involvement: ['Satisfecho' 'Insatisfecho' 'Muy satisfecho' 'Nada satisfecho']\n",
      "job_satisfaction: ['Muy satisfecho' 'Insatisfecho' 'Satisfecho' 'Nada satisfecho' nan]\n",
      "work_life_balance: ['Nada satisfecho' 'Satisfecho' 'Insatisfecho' 'Muy satisfecho']\n",
      "education: ['Educaci√≥n b√°sica' 'Sin estudios' 'Estudios universitarios'\n",
      " 'FP/Bachiller' 'Postgrado']\n",
      "job_level: ['Junior' 'Becario' 'Senior' 'Manager' 'Director']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DEFINICI√ìN DE MAPEOS PARA VARIABLES ORDINALES\n",
    "# ============================================================================\n",
    "\n",
    "# Mapeo para variables de satisfacci√≥n (escala 1-4)\n",
    "satisfaction_map = {\n",
    "    1: \"Nada satisfecho\",\n",
    "    2: \"Insatisfecho\",\n",
    "    3: \"Satisfecho\",\n",
    "    4: \"Muy satisfecho\",\n",
    "}\n",
    "\n",
    "# Mapeo para nivel educativo (escala 1-5)\n",
    "education_map = {\n",
    "    1: \"Sin estudios\",\n",
    "    2: \"Educaci√≥n b√°sica\",\n",
    "    3: \"FP/Bachiller\",\n",
    "    4: \"Estudios universitarios\",\n",
    "    5: \"Postgrado\",\n",
    "}\n",
    "\n",
    "# Mapeo para nivel de puesto (escala 1-5)\n",
    "job_level_map = {\n",
    "    1: \"Becario\",\n",
    "    2: \"Junior\",\n",
    "    3: \"Senior\",\n",
    "    4: \"Manager\",\n",
    "    5: \"Director\",\n",
    "}\n",
    "\n",
    "# Lista de columnas que usan la escala de satisfacci√≥n\n",
    "satisfaction_cols = [\n",
    "    \"env_satisfaction\",      # Satisfacci√≥n con el ambiente\n",
    "    \"job_involvement\",       # Involucramiento en el trabajo\n",
    "    \"job_satisfaction\",      # Satisfacci√≥n laboral\n",
    "    \"performance_score\",     # Autoevaluaci√≥n de desempe√±o\n",
    "    \"rel_satisfaction\",      # Satisfacci√≥n con relaciones\n",
    "    \"work_life_balance\",     # Balance vida-trabajo\n",
    "]\n",
    "\n",
    "# Construir diccionario completo de mapeos\n",
    "# Todas las columnas de satisfacci√≥n usan el mismo mapeo\n",
    "mapeos_ordinales = {col: satisfaction_map for col in satisfaction_cols}\n",
    "\n",
    "# A√±adir mapeos espec√≠ficos para educaci√≥n y nivel de puesto\n",
    "mapeos_ordinales[\"education\"] = education_map\n",
    "mapeos_ordinales[\"job_level\"] = job_level_map\n",
    "\n",
    "# Aplicar todos los mapeos al DataFrame\n",
    "df = mapear_columnas_ordinales(df, mapeos_ordinales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imputacion_categoricas",
   "metadata": {},
   "source": [
    "---\n",
    "## **8. IMPUTACI√ìN DE VALORES NULOS EN VARIABLES CATEG√ìRICAS**\n",
    "\n",
    "Rellenamos valores faltantes en variables categ√≥ricas siguiendo reglas basadas en:\n",
    "- **Porcentaje de nulos**: alto (>20%), medio (5-20%), bajo (<5%)\n",
    "- **Dominancia de la moda**: qu√© tan frecuente es la categor√≠a m√°s com√∫n\n",
    "- **Ventaja de la moda**: diferencia con la segunda categor√≠a m√°s frecuente\n",
    "\n",
    "**Estrategias:**\n",
    "- Muchos nulos (>20%) ‚Üí `Unknown`\n",
    "- Pocos nulos con moda dominante ‚Üí Moda\n",
    "- Resto de casos ‚Üí `Unknown`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bfebf779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputar_categoricas(df, columnas, umbral_nulos_alto=0.20, umbral_nulos_bajo=0.05,\n",
    "                        umbral_moda_bajo=0.50, umbral_moda_medio=0.60, umbral_ventaja=0.20,\n",
    "                        etiqueta_unknown=\"Unknown\"):\n",
    "    \"\"\"\n",
    "    Imputa valores nulos en variables categ√≥ricas siguiendo reglas justificables estad√≠sticamente.\n",
    "    \n",
    "    L√ìGICA DE IMPUTACI√ìN:\n",
    "    \n",
    "    1) % de nulos ALTO (> 20%):\n",
    "       ‚Üí Imputar con 'Unknown'\n",
    "       ‚Üí Justificaci√≥n: Con muchos nulos, imputar por moda inventa demasiada informaci√≥n\n",
    "    \n",
    "    2) % de nulos BAJO (‚â§ 5%) o MEDIO (5-20%):\n",
    "       ‚Üí Imputar con MODA solo si hay una categor√≠a verdaderamente dominante\n",
    "       ‚Üí Condiciones para usar moda:\n",
    "          a) La moda debe superar un umbral m√≠nimo:\n",
    "             - Nulos bajos: moda ‚â• 50% del total\n",
    "             - Nulos medios: moda ‚â• 60% del total (m√°s exigente)\n",
    "          b) La moda debe tener ventaja sobre la 2¬™ categor√≠a:\n",
    "             - (% moda - % segunda) ‚â• 20 puntos porcentuales\n",
    "       ‚Üí Si NO se cumplen estas condiciones ‚Üí 'Unknown'\n",
    "\n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame a procesar (se modifica)\n",
    "    columnas : list[str]\n",
    "        Lista de columnas categ√≥ricas donde imputar nulos\n",
    "    umbral_nulos_alto : float, default=0.20\n",
    "        Umbral para considerar % de nulos como \"alto\"\n",
    "    umbral_nulos_bajo : float, default=0.05\n",
    "        Umbral para considerar % de nulos como \"bajo\"\n",
    "    umbral_moda_bajo : float, default=0.50\n",
    "        % m√≠nimo que debe tener la moda cuando los nulos son bajos\n",
    "    umbral_moda_medio : float, default=0.60\n",
    "        % m√≠nimo que debe tener la moda cuando los nulos son medios\n",
    "    umbral_ventaja : float, default=0.20\n",
    "        Ventaja m√≠nima (en puntos porcentuales) entre moda y 2¬™ categor√≠a\n",
    "    etiqueta_unknown : str, default=\"Unknown\"\n",
    "        Etiqueta para imputar cuando no se usa la moda\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame con nulos imputados en las columnas especificadas\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(df)\n",
    "\n",
    "    for col in columnas:\n",
    "        print(f\"\\nüìå Analizando columna: {col}\")\n",
    "        \n",
    "        # Validar que la columna existe\n",
    "        if col not in df.columns:\n",
    "            print(f\"‚ùå La columna {col} no existe en el DataFrame. Se omite.\")\n",
    "            continue\n",
    "\n",
    "        # Contar nulos y calcular porcentaje\n",
    "        nulos = df[col].isnull().sum()\n",
    "        porcentaje_nulos = nulos / total if total > 0 else 0\n",
    "\n",
    "        print(f\"   ‚Üí Nulos: {nulos} de {total} ({porcentaje_nulos:.2%})\")\n",
    "\n",
    "        # ================================================================\n",
    "        # REGLA 1: Muchos nulos ‚Üí Unknown directamente\n",
    "        # ================================================================\n",
    "        if porcentaje_nulos > umbral_nulos_alto:\n",
    "            print(\n",
    "                f\"   üî¥ Porcentaje de nulos > {umbral_nulos_alto:.0%} \"\n",
    "                f\"‚Üí se crea la categor√≠a '{etiqueta_unknown}'\"\n",
    "            )\n",
    "            df[col] = df[col].fillna(etiqueta_unknown)\n",
    "            continue\n",
    "        \n",
    "        # Calcular frecuencias de categor√≠as (sin contar nulos)\n",
    "        valores = df[col].value_counts(dropna=True)\n",
    "\n",
    "        # Si no hay valores no nulos, imputar con Unknown\n",
    "        if len(valores) == 0:\n",
    "            print(\n",
    "                f\"   üî¥ No hay valores no nulos para decidir moda \"\n",
    "                f\"‚Üí se crea la categor√≠a '{etiqueta_unknown}'\"\n",
    "            )\n",
    "            df[col] = df[col].fillna(etiqueta_unknown)\n",
    "            continue\n",
    "\n",
    "        # Obtener moda (categor√≠a m√°s frecuente)\n",
    "        primero = valores.iloc[0]  # Frecuencia absoluta de la moda\n",
    "        pct_primero = primero / total  # Proporci√≥n sobre el total de filas\n",
    "\n",
    "        # Obtener segunda categor√≠a m√°s frecuente (si existe)\n",
    "        if len(valores) > 1:\n",
    "            segundo = valores.iloc[1]\n",
    "            pct_segundo = segundo / total\n",
    "        else:\n",
    "            pct_segundo = 0.0\n",
    "\n",
    "        # Calcular ventaja de la moda sobre la 2¬™ categor√≠a\n",
    "        ventaja = pct_primero - pct_segundo\n",
    "\n",
    "        # Mostrar informaci√≥n de las categor√≠as principales\n",
    "        print(f\"   ‚Üí Moda: {valores.index[0]} ({pct_primero:.2%})\")\n",
    "        print(f\"   ‚Üí 2¬™ categor√≠a: {valores.index[1] if len(valores) > 1 else 'No existe'} ({pct_segundo:.2%})\")\n",
    "        print(f\"   ‚Üí Ventaja de la moda: {ventaja:.2%}\")\n",
    "\n",
    "        # ================================================================\n",
    "        # REGLA 2: Determinar umbral de moda seg√∫n % de nulos\n",
    "        # ================================================================\n",
    "        if porcentaje_nulos <= umbral_nulos_bajo:\n",
    "            umbral_moda = umbral_moda_bajo\n",
    "            print(\n",
    "                f\"   ‚Üí Nulos bajos (‚â§ {umbral_nulos_bajo:.0%}), \"\n",
    "                f\"umbral de moda requerido: {umbral_moda:.0%}\"\n",
    "            )\n",
    "        else:  # Nulos medios (entre bajo y alto)\n",
    "            umbral_moda = umbral_moda_medio\n",
    "            print(\n",
    "                f\"   ‚Üí Nulos medios (> {umbral_nulos_bajo:.0%} y ‚â§ {umbral_nulos_alto:.0%}), \"\n",
    "                f\"umbral de moda requerido: {umbral_moda:.0%}\"\n",
    "            )\n",
    "        \n",
    "        # ================================================================\n",
    "        # REGLA 3: Imputar por moda solo si es dominante Y tiene ventaja\n",
    "        # ================================================================\n",
    "        if (pct_primero >= umbral_moda) and (ventaja >= umbral_ventaja):\n",
    "            moda = df[col].mode(dropna=True)[0]\n",
    "            print(\n",
    "                f\"   üü¢ La moda es dominante y con ventaja suficiente \"\n",
    "                f\"(‚â• {umbral_ventaja:.0%}) ‚Üí se imputan nulos con '{moda}'\"\n",
    "            )\n",
    "            df[col] = df[col].fillna(moda)\n",
    "        else:\n",
    "            print(\n",
    "                f\"   üü° La moda NO es lo suficientemente dominante \"\n",
    "                f\"‚Üí se crea la categor√≠a '{etiqueta_unknown}'\"\n",
    "            )\n",
    "            df[col] = df[col].fillna(etiqueta_unknown)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f2073d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Analizando columna: business_travel\n",
      "   ‚Üí Nulos: 117 de 1470 (7.96%)\n",
      "   ‚Üí Moda: Rarely (64.69%)\n",
      "   ‚Üí 2¬™ categor√≠a: Frequently (17.89%)\n",
      "   ‚Üí Ventaja de la moda: 46.80%\n",
      "   ‚Üí Nulos medios (> 5% y ‚â§ 20%), umbral de moda requerido: 60%\n",
      "   üü¢ La moda es dominante y con ventaja suficiente (‚â• 20%) ‚Üí se imputan nulos con 'Rarely'\n",
      "\n",
      "üìå Analizando columna: department\n",
      "   ‚Üí Nulos: 29 de 1470 (1.97%)\n",
      "   ‚Üí Moda: Research & Development (63.88%)\n",
      "   ‚Üí 2¬™ categor√≠a: Sales (29.86%)\n",
      "   ‚Üí Ventaja de la moda: 34.01%\n",
      "   ‚Üí Nulos bajos (‚â§ 5%), umbral de moda requerido: 50%\n",
      "   üü¢ La moda es dominante y con ventaja suficiente (‚â• 20%) ‚Üí se imputan nulos con 'Research & Development'\n",
      "\n",
      "üìå Analizando columna: education\n",
      "   ‚Üí Nulos: 0 de 1470 (0.00%)\n",
      "   ‚Üí Moda: FP/Bachiller (38.91%)\n",
      "   ‚Üí 2¬™ categor√≠a: Estudios universitarios (27.07%)\n",
      "   ‚Üí Ventaja de la moda: 11.84%\n",
      "   ‚Üí Nulos bajos (‚â§ 5%), umbral de moda requerido: 50%\n",
      "   üü° La moda NO es lo suficientemente dominante ‚Üí se crea la categor√≠a 'Unknown'\n",
      "\n",
      "üìå Analizando columna: education_field\n",
      "   ‚Üí Nulos: 58 de 1470 (3.95%)\n",
      "   ‚Üí Moda: Life Sciences (39.52%)\n",
      "   ‚Üí 2¬™ categor√≠a: Medical (30.41%)\n",
      "   ‚Üí Ventaja de la moda: 9.12%\n",
      "   ‚Üí Nulos bajos (‚â§ 5%), umbral de moda requerido: 50%\n",
      "   üü° La moda NO es lo suficientemente dominante ‚Üí se crea la categor√≠a 'Unknown'\n",
      "\n",
      "üìå Analizando columna: gender\n",
      "   ‚Üí Nulos: 0 de 1470 (0.00%)\n",
      "   ‚Üí Moda: Male (60.00%)\n",
      "   ‚Üí 2¬™ categor√≠a: Female (40.00%)\n",
      "   ‚Üí Ventaja de la moda: 20.00%\n",
      "   ‚Üí Nulos bajos (‚â§ 5%), umbral de moda requerido: 50%\n",
      "   üü° La moda NO es lo suficientemente dominante ‚Üí se crea la categor√≠a 'Unknown'\n",
      "\n",
      "üìå Analizando columna: job_involvement\n",
      "   ‚Üí Nulos: 0 de 1470 (0.00%)\n",
      "   ‚Üí Moda: Satisfecho (59.05%)\n",
      "   ‚Üí 2¬™ categor√≠a: Insatisfecho (25.51%)\n",
      "   ‚Üí Ventaja de la moda: 33.54%\n",
      "   ‚Üí Nulos bajos (‚â§ 5%), umbral de moda requerido: 50%\n",
      "   üü¢ La moda es dominante y con ventaja suficiente (‚â• 20%) ‚Üí se imputan nulos con 'Satisfecho'\n",
      "\n",
      "üìå Analizando columna: job_level\n",
      "   ‚Üí Nulos: 0 de 1470 (0.00%)\n",
      "   ‚Üí Moda: Becario (36.94%)\n",
      "   ‚Üí 2¬™ categor√≠a: Junior (36.33%)\n",
      "   ‚Üí Ventaja de la moda: 0.61%\n",
      "   ‚Üí Nulos bajos (‚â§ 5%), umbral de moda requerido: 50%\n",
      "   üü° La moda NO es lo suficientemente dominante ‚Üí se crea la categor√≠a 'Unknown'\n",
      "\n",
      "üìå Analizando columna: job_role\n",
      "   ‚Üí Nulos: 0 de 1470 (0.00%)\n",
      "   ‚Üí Moda: Sales Executive (22.18%)\n",
      "   ‚Üí 2¬™ categor√≠a: Research Scientist (19.86%)\n",
      "   ‚Üí Ventaja de la moda: 2.31%\n",
      "   ‚Üí Nulos bajos (‚â§ 5%), umbral de moda requerido: 50%\n",
      "   üü° La moda NO es lo suficientemente dominante ‚Üí se crea la categor√≠a 'Unknown'\n",
      "\n",
      "üìå Analizando columna: job_satisfaction\n",
      "   ‚Üí Nulos: 29 de 1470 (1.97%)\n",
      "   ‚Üí Moda: Muy satisfecho (30.95%)\n",
      "   ‚Üí 2¬™ categor√≠a: Satisfecho (29.12%)\n",
      "   ‚Üí Ventaja de la moda: 1.84%\n",
      "   ‚Üí Nulos bajos (‚â§ 5%), umbral de moda requerido: 50%\n",
      "   üü° La moda NO es lo suficientemente dominante ‚Üí se crea la categor√≠a 'Unknown'\n",
      "\n",
      "üìå Analizando columna: marital_status\n",
      "   ‚Üí Nulos: 132 de 1470 (8.98%)\n",
      "   ‚Üí Moda: Married (41.22%)\n",
      "   ‚Üí 2¬™ categor√≠a: Single (29.66%)\n",
      "   ‚Üí Ventaja de la moda: 11.56%\n",
      "   ‚Üí Nulos medios (> 5% y ‚â§ 20%), umbral de moda requerido: 60%\n",
      "   üü° La moda NO es lo suficientemente dominante ‚Üí se crea la categor√≠a 'Unknown'\n",
      "\n",
      "üìå Analizando columna: over_time\n",
      "   ‚Üí Nulos: 44 de 1470 (2.99%)\n",
      "   ‚Üí Moda: No (69.46%)\n",
      "   ‚Üí 2¬™ categor√≠a: Yes (27.55%)\n",
      "   ‚Üí Ventaja de la moda: 41.90%\n",
      "   ‚Üí Nulos bajos (‚â§ 5%), umbral de moda requerido: 50%\n",
      "   üü¢ La moda es dominante y con ventaja suficiente (‚â• 20%) ‚Üí se imputan nulos con 'No'\n",
      "\n",
      "üìå Analizando columna: work_life_balance\n",
      "   ‚Üí Nulos: 0 de 1470 (0.00%)\n",
      "   ‚Üí Moda: Satisfecho (60.75%)\n",
      "   ‚Üí 2¬™ categor√≠a: Insatisfecho (23.40%)\n",
      "   ‚Üí Ventaja de la moda: 37.35%\n",
      "   ‚Üí Nulos bajos (‚â§ 5%), umbral de moda requerido: 50%\n",
      "   üü¢ La moda es dominante y con ventaja suficiente (‚â• 20%) ‚Üí se imputan nulos con 'Satisfecho'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PREPARACI√ìN Y APLICACI√ìN DE IMPUTACI√ìN CATEG√ìRICA\n",
    "# ============================================================================\n",
    "\n",
    "# Paso 1: Identificar columnas categ√≥ricas (object o category)\n",
    "cols_cat = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# Paso 2: Excluir la variable objetivo 'attrition' de la imputaci√≥n\n",
    "# (no queremos imputar la variable que es objeto de an√°lisis)\n",
    "cols_cat = [c for c in cols_cat if c.lower() != \"attrition\"]\n",
    "\n",
    "# Paso 3: Normalizar espacios en blanco vac√≠os a NaN\n",
    "# Algunos datasets tienen celdas con solo espacios que pandas no detecta como nulos\n",
    "# El regex r'^\\s*$' busca cadenas que solo contengan espacios (o est√©n vac√≠as)\n",
    "df[cols_cat] = df[cols_cat].replace(r'^\\s*$', pd.NA, regex=True)\n",
    "\n",
    "# Paso 4: Aplicar imputaci√≥n con las reglas definidas\n",
    "df = imputar_categoricas(df, cols_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imputacion_numericas",
   "metadata": {},
   "source": [
    "---\n",
    "## **9. IMPUTACI√ìN DE VALORES NULOS EN VARIABLES NUM√âRICAS**\n",
    "\n",
    "Rellenamos valores faltantes en variables num√©ricas usando estrategias robustas:\n",
    "\n",
    "**Estrategias seg√∫n % de nulos:**\n",
    "- **Nulos bajos (‚â§5%)**: Mediana (robusta a outliers)\n",
    "- **Nulos medios (5-20%)**: KNN con escalado (usa informaci√≥n de registros similares)\n",
    "- **Nulos altos (>20%)**: Mediana + indicador de missingness\n",
    "\n",
    "**¬øPor qu√© escalado con KNN?**\n",
    "KNN calcula distancias entre filas. Si una variable est√° en escala 0-10 y otra en 0-10,000,\n",
    "la segunda dominar√≠a el c√°lculo. El escalado (StandardScaler) pone todas las variables\n",
    "en la misma escala antes de calcular similitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e084c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputar_numericas(df, columnas, umbral_nulos_bajo=0.05, umbral_nulos_alto=0.20,\n",
    "                      n_neighbors=5, crear_indicador_missing=True, usar_knn_en_alto=False):\n",
    "    \"\"\"\n",
    "    Imputa valores nulos en variables num√©ricas con estrategias robustas.\n",
    "    \n",
    "    L√ìGICA DE IMPUTACI√ìN:\n",
    "    \n",
    "    1) % de nulos BAJO (‚â§ 5%):\n",
    "       ‚Üí Imputar con MEDIANA (SimpleImputer)\n",
    "       ‚Üí Justificaci√≥n: Con pocos nulos, la mediana es estable y robusta a outliers\n",
    "    \n",
    "    2) % de nulos MODERADO (5-20%):\n",
    "       ‚Üí Imputar con KNN (KNNImputer) usando escalado\n",
    "       ‚Üí Justificaci√≥n: KNN aprovecha informaci√≥n de registros similares\n",
    "       ‚Üí Requiere escalado porque KNN usa distancias entre filas\n",
    "    \n",
    "    3) % de nulos ALTO (> 20%):\n",
    "       ‚Üí Crear variable indicadora de missingness (col_missing: 0/1)\n",
    "       ‚Üí Imputar con MEDIANA (por defecto) o KNN (si usar_knn_en_alto=True)\n",
    "       ‚Üí Justificaci√≥n: La presencia de nulo puede ser informativa\n",
    "    \n",
    "    IMPORTANTE SOBRE KNN Y ESCALADO:\n",
    "    KNN calcula similitud entre filas usando distancias. Si las columnas est√°n en\n",
    "    escalas diferentes (ej: una en 0-10, otra en 0-10000), la de mayor rango\n",
    "    dominar√≠a el c√°lculo. Por eso:\n",
    "      1. Escalamos (StandardScaler): (x - media) / desviaci√≥n\n",
    "      2. Aplicamos KNN en el espacio escalado\n",
    "      3. Desescalamos para volver a unidades originales\n",
    "\n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame a procesar (se modifica)\n",
    "    columnas : list[str]\n",
    "        Lista de columnas num√©ricas donde imputar nulos\n",
    "    umbral_nulos_bajo : float, default=0.05\n",
    "        Umbral para % de nulos \"bajo\"\n",
    "    umbral_nulos_alto : float, default=0.20\n",
    "        Umbral para % de nulos \"alto\"\n",
    "    n_neighbors : int, default=5\n",
    "        N√∫mero de vecinos (k) para KNNImputer\n",
    "    crear_indicador_missing : bool, default=True\n",
    "        Si True, crea columna col_missing cuando % nulos es alto\n",
    "    usar_knn_en_alto : bool, default=False\n",
    "        Si True, usa KNN tambi√©n cuando % nulos es alto (m√°s costoso)\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame con nulos imputados en las columnas especificadas\n",
    "    \"\"\"\n",
    "    \n",
    "    #Guardar los tipos originales para restaurar a int de nuevo tras la imputaci√≥n\n",
    "    dtypes_originales = df.dtypes.copy()\n",
    "    total = len(df)\n",
    "\n",
    "    # Filtrar solo columnas que existen \n",
    "    columnas_validas = df[columnas].select_dtypes(include=[np.number]).columns.tolist()\n",
    "    columnas_no_encontradas = [c for c in columnas if c not in df.columns]\n",
    "    \n",
    "    for c in columnas_no_encontradas:\n",
    "        print(f\"{c} no existe en el DataFrame. Se omite.\")\n",
    "\n",
    "    # Verificar que son num√©ricas\n",
    "    cols_num_df = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    columnas_validas = [c for c in columnas_validas if c in cols_num_df]\n",
    "\n",
    "    if len(columnas_validas) == 0:\n",
    "        print(\"No hay columnas num√©ricas v√°lidas para imputar.\")\n",
    "        return df\n",
    "\n",
    "    # Preparar imputador de mediana (se reutiliza)\n",
    "    imputer_mediana = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    # Para KNN usamos todas las num√©ricas como contexto (mejora la similitud)\n",
    "    cols_num_contexto = cols_num_df\n",
    "\n",
    "    for col in columnas_validas:\n",
    "        print(f\"\\nüìå Analizando columna num√©rica: {col}\")\n",
    "\n",
    "        nulos = df[col].isnull().sum()\n",
    "        porcentaje_nulos = nulos / total if total > 0 else 0\n",
    "        print(f\"   ‚Üí Nulos: {nulos} de {total} ({porcentaje_nulos:.2%})\")\n",
    "\n",
    "        # ================================================================\n",
    "        # CASO 1: Nulos bajos ‚Üí MEDIANA\n",
    "        # ================================================================\n",
    "        if porcentaje_nulos <= umbral_nulos_bajo:\n",
    "            print(\n",
    "                f\"   üü¢ Nulos bajos (‚â§ {umbral_nulos_bajo:.0%}) \"\n",
    "                f\"‚Üí imputaci√≥n con MEDIANA (SimpleImputer)\"\n",
    "            )\n",
    "            df[[col]] = imputer_mediana.fit_transform(df[[col]])\n",
    "            continue\n",
    "\n",
    "        # ================================================================\n",
    "        # CASO 2: Nulos moderados ‚Üí KNN con ESCALADO\n",
    "        # ================================================================\n",
    "        if porcentaje_nulos <= umbral_nulos_alto:\n",
    "            print(\n",
    "                f\"   üü° Nulos moderados (> {umbral_nulos_bajo:.0%} y ‚â§ {umbral_nulos_alto:.0%}) \"\n",
    "                f\"‚Üí imputaci√≥n con KNN (k={n_neighbors}) + ESCALADO\"\n",
    "            )\n",
    "\n",
    "            # Paso 1: Extraer bloque num√©rico completo (para contexto de similitud)\n",
    "            X = df[cols_num_contexto].copy()\n",
    "\n",
    "            # Paso 2: ESCALAR - poner todas las columnas en escala comparable\n",
    "            # StandardScaler: z = (x - media) / desviaci√≥n_est√°ndar\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "            # Paso 3: Imputar usando KNN en el espacio escalado\n",
    "            knn = KNNImputer(n_neighbors=n_neighbors)\n",
    "            X_imputed_scaled = knn.fit_transform(X_scaled)\n",
    "\n",
    "            # Paso 4: DESESCALAR - volver a las unidades originales\n",
    "            X_imputed = scaler.inverse_transform(X_imputed_scaled)\n",
    "\n",
    "            # Paso 5: Convertir de vuelta a DataFrame\n",
    "            X_imputed = pd.DataFrame(X_imputed, columns=cols_num_contexto, index=df.index)\n",
    "\n",
    "            # Paso 6: Guardar solo la columna objetivo (no tocamos otras num√©ricas)\n",
    "            df[col] = X_imputed[col]\n",
    "\n",
    "            print(f\"   ‚úÖ {col} imputada con KNN + escalado (solo se asigna esta columna).\")\n",
    "            continue\n",
    "\n",
    "        # ================================================================\n",
    "        # CASO 3: Nulos altos ‚Üí INDICADOR + MEDIANA/KNN\n",
    "        # ================================================================\n",
    "        print(\n",
    "            f\"   üî¥ Nulos altos (> {umbral_nulos_alto:.0%}) \"\n",
    "            f\"‚Üí se considera missingness + imputaci√≥n robusta\"\n",
    "        )\n",
    "\n",
    "        # Crear variable indicadora de nulo (1 si era nulo, 0 si no)\n",
    "        if crear_indicador_missing:\n",
    "            indicador = f\"{col}_missing\"\n",
    "            df[indicador] = df[col].isnull().astype(int)\n",
    "            print(f\"   ‚Üí Se crea indicador de missingness: {indicador} (1=nulo, 0=no nulo)\")\n",
    "\n",
    "        # Decidir m√©todo de imputaci√≥n\n",
    "        if usar_knn_en_alto:\n",
    "            print(\n",
    "                f\"   üü† usar_knn_en_alto=True \"\n",
    "                f\"‚Üí imputaci√≥n con KNN (k={n_neighbors}) + ESCALADO\"\n",
    "            )\n",
    "\n",
    "            X = df[cols_num_contexto].copy()\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "            knn = KNNImputer(n_neighbors=n_neighbors)\n",
    "            X_imputed_scaled = knn.fit_transform(X_scaled)\n",
    "\n",
    "            X_imputed = scaler.inverse_transform(X_imputed_scaled)\n",
    "            X_imputed = pd.DataFrame(X_imputed, columns=cols_num_contexto, index=df.index)\n",
    "\n",
    "            df[col] = X_imputed[col]\n",
    "            print(f\"   ‚úÖ {col} imputada con KNN + escalado (solo se asigna esta columna).\")\n",
    "\n",
    "        else:\n",
    "            print(\"   üü† Se imputa con MEDIANA (SimpleImputer) por estabilidad.\")\n",
    "            df[[col]] = imputer_mediana.fit_transform(df[[col]])\n",
    "\n",
    "\n",
    "    # Restaurar tipos de datos orginales (int + redondear + convertir)\n",
    "    for col in columnas_validas:\n",
    "        if col in dtypes_originales:\n",
    "            # Si originalmente era entero ‚Üí restaurar\n",
    "            if pd.api.types.is_integer_dtype(dtypes_originales[col]):\n",
    "                print(f\"   üîÑ Restaurando tipo entero en: {col}\")\n",
    "                df[col] = (\n",
    "                    df[col]\n",
    "                    .round()          # eliminar decimales de KNN\n",
    "                    .astype(\"Int64\")  # volver a int\n",
    "                )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8648696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Analizando columna num√©rica: age\n",
      "   ‚Üí Nulos: 73 de 1470 (4.97%)\n",
      "   üü¢ Nulos bajos (‚â§ 5%) ‚Üí imputaci√≥n con MEDIANA (SimpleImputer)\n",
      "\n",
      "üìå Analizando columna num√©rica: monthly_income\n",
      "   ‚Üí Nulos: 14 de 1470 (0.95%)\n",
      "   üü¢ Nulos bajos (‚â§ 5%) ‚Üí imputaci√≥n con MEDIANA (SimpleImputer)\n",
      "\n",
      "üìå Analizando columna num√©rica: training_times_last_year\n",
      "   ‚Üí Nulos: 88 de 1470 (5.99%)\n",
      "   üü° Nulos moderados (> 5% y ‚â§ 20%) ‚Üí imputaci√≥n con KNN (k=5) + ESCALADO\n",
      "   ‚úÖ training_times_last_year imputada con KNN + escalado (solo se asigna esta columna).\n",
      "\n",
      "üìå Analizando columna num√©rica: years_with_curr_manager\n",
      "   ‚Üí Nulos: 147 de 1470 (10.00%)\n",
      "   üü° Nulos moderados (> 5% y ‚â§ 20%) ‚Üí imputaci√≥n con KNN (k=5) + ESCALADO\n",
      "   ‚úÖ years_with_curr_manager imputada con KNN + escalado (solo se asigna esta columna).\n",
      "   üîÑ Restaurando tipo entero en: age\n",
      "   üîÑ Restaurando tipo entero en: training_times_last_year\n",
      "   üîÑ Restaurando tipo entero en: years_with_curr_manager\n",
      "‚úÖ Proceso finalizado. Nulos num√©ricos restantes: 0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PREPARACI√ìN Y APLICACI√ìN DE IMPUTACI√ìN NUM√âRICA\n",
    "# ============================================================================\n",
    "\n",
    "# Paso 1: Identificar columnas num√©ricas (int o float)\n",
    "cols_num = df.select_dtypes(include=[np.number]).columns[df.select_dtypes(include=[np.number]).isnull().any()].tolist()\n",
    "\n",
    "# Paso 2: Definir las columnas espec√≠ficas que queremos procesar\n",
    "# (Podemos usar todas las num√©ricas detectadas o una lista personalizada)\n",
    "# cols_a_imputar_num = ['age', 'monthly_income', 'total_working_years', ...] \n",
    "cols_a_imputar_num = cols_num \n",
    "\n",
    "# Paso 3: Aplicar imputaci√≥n con l√≥gica de escenarios (Mediana / KNN / Indicador)\n",
    "df = imputar_numericas(\n",
    "    df, \n",
    "    columnas=cols_a_imputar_num,\n",
    "    umbral_nulos_bajo=0.05, \n",
    "    umbral_nulos_alto=0.20,\n",
    "    n_neighbors=5,\n",
    "    crear_indicador_missing=True,\n",
    "    usar_knn_en_alto=False\n",
    ")\n",
    "\n",
    "# Paso 4: Verificaci√≥n final de la limpieza\n",
    "# Comprobamos que no queden nulos en las columnas procesadas\n",
    "nulos_restantes = df[cols_a_imputar_num].isnull().sum().sum()\n",
    "print(f\"‚úÖ Proceso finalizado. Nulos num√©ricos restantes: {nulos_restantes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34bb2c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1470 entries, 1 to 2068\n",
      "Data columns (total 30 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   age                         1470 non-null   Int64  \n",
      " 1   attrition                   1470 non-null   object \n",
      " 2   business_travel             1470 non-null   object \n",
      " 3   daily_rate                  1470 non-null   float64\n",
      " 4   department                  1470 non-null   object \n",
      " 5   distance_from_home          1470 non-null   int64  \n",
      " 6   education                   1470 non-null   object \n",
      " 7   education_field             1470 non-null   object \n",
      " 8   environment_satisfaction    1470 non-null   int64  \n",
      " 9   gender                      1470 non-null   object \n",
      " 10  hourly_rate                 1470 non-null   float64\n",
      " 11  job_involvement             1470 non-null   object \n",
      " 12  job_level                   1470 non-null   object \n",
      " 13  job_role                    1470 non-null   object \n",
      " 14  job_satisfaction            1470 non-null   object \n",
      " 15  marital_status              1470 non-null   object \n",
      " 16  monthly_income              1470 non-null   float64\n",
      " 17  num_companies_worked        1470 non-null   int64  \n",
      " 18  over_time                   1470 non-null   object \n",
      " 19  percent_salary_hike         1470 non-null   int64  \n",
      " 20  performance_rating          1470 non-null   int64  \n",
      " 21  relationship_satisfaction   1470 non-null   int64  \n",
      " 22  stock_option_level          1470 non-null   int64  \n",
      " 23  total_working_years         1470 non-null   int64  \n",
      " 24  training_times_last_year    1470 non-null   Int64  \n",
      " 25  work_life_balance           1470 non-null   object \n",
      " 26  years_at_company            1470 non-null   int64  \n",
      " 27  years_in_current_role       1470 non-null   int64  \n",
      " 28  years_since_last_promotion  1470 non-null   int64  \n",
      " 29  years_with_curr_manager     1470 non-null   Int64  \n",
      "dtypes: Int64(3), float64(3), int64(11), object(13)\n",
      "memory usage: 360.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funcion_limpieza_general",
   "metadata": {},
   "source": [
    "---\n",
    "## **10. FUNCI√ìN DE LIMPIEZA GENERAL**\n",
    "\n",
    "Esta funci√≥n integra todos los pasos anteriores en un solo proceso automatizado.\n",
    "Es √∫til cuando quieres aplicar todo el flujo de limpieza de una sola vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9facd556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza_general(\n",
    "    df,\n",
    "    id_columna='employee_number',\n",
    "    mapeo_tipos=None,\n",
    "    mapeos_texto=None,\n",
    "    mapeos_ordinales=None,\n",
    "    columnas_categoricas_nulos=None,\n",
    "    columnas_numericas_nulos=None,\n",
    "    mostrar_resumen=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Ejecuta el proceso completo de limpieza de datos en un DataFrame.\n",
    "    \n",
    "    Esta funci√≥n orquesta todos los pasos de limpieza en el orden correcto:\n",
    "    1. Normalizaci√≥n de nombres de columnas (snake_case)\n",
    "    2. Establecer columna ID como √≠ndice\n",
    "    3. Eliminaci√≥n de filas duplicadas\n",
    "    4. Eliminaci√≥n de columnas sin aporte anal√≠tico\n",
    "    5. Conversi√≥n de tipos de datos\n",
    "    6. Normalizaci√≥n de columnas de texto\n",
    "    7. Mapeo de columnas ordinales\n",
    "    8. Imputaci√≥n de nulos en categ√≥ricas\n",
    "    9. Imputaci√≥n de nulos en num√©ricas\n",
    "\n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame original a limpiar\n",
    "    id_columna : str, default='employee_number'\n",
    "        Nombre de la columna que se usar√° como √≠ndice\n",
    "    mapeo_tipos : dict, optional\n",
    "        Diccionario de conversi√≥n de tipos {'columna': tipo}\n",
    "    mapeos_texto : dict, optional\n",
    "        Diccionario de reemplazos en texto {'columna': {'viejo': 'nuevo'}}\n",
    "    mapeos_ordinales : dict, optional\n",
    "        Diccionario de mapeos ordinales {'columna': {1: 'etiqueta'}}\n",
    "    columnas_categoricas_nulos : list, optional\n",
    "        Lista de columnas categ√≥ricas donde imputar nulos\n",
    "    columnas_numericas_nulos : list, optional\n",
    "        Lista de columnas num√©ricas donde imputar nulos\n",
    "    mostrar_resumen : bool, default=True\n",
    "        Si True, imprime resumen de cada paso\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame limpio y listo para an√°lisis\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear copia para no modificar el DataFrame original\n",
    "    df = df.copy()\n",
    "\n",
    "    # PASO 1: Normalizar nombres de columnas\n",
    "    df.columns = normalizar_nombres_columnas(df.columns.tolist(), mostrar_resumen=mostrar_resumen)\n",
    "\n",
    "    # PASO 2: Establecer ID como √≠ndice\n",
    "    df = usar_columna_como_indice(df, columna_original=id_columna, indice='id')\n",
    "\n",
    "    # PASO 3: Eliminar duplicados\n",
    "    df = eliminar_filas_duplicadas(df)\n",
    "\n",
    "    # PASO 4: Eliminar columnas sin aporte anal√≠tico\n",
    "    df = eliminar_columnas_sin_aporte_analitico(df)\n",
    "\n",
    "    # PASO 5: Conversi√≥n de tipos (si se proporcion√≥ mapeo)\n",
    "    if mapeo_tipos:\n",
    "        df = convertir_tipos_columnas(df, mapeo_tipos, mostrar_resumen=mostrar_resumen)\n",
    "\n",
    "    # PASO 6: Normalizaci√≥n de texto (si se proporcionaron mapeos)\n",
    "    if mapeos_texto:\n",
    "        df = normalizar_columnas_texto(df, mapeos_reemplazo=mapeos_texto, mostrar_resumen=mostrar_resumen)\n",
    "\n",
    "    # PASO 7: Mapeo de ordinales (si se proporcionaron mapeos)\n",
    "    if mapeos_ordinales:\n",
    "        df = mapear_columnas_ordinales(df, mapeos_ordinales, mostrar_resumen=mostrar_resumen)\n",
    "\n",
    "    # PASO 8: Imputaci√≥n de categ√≥ricas (si se especificaron columnas)\n",
    "    if columnas_categoricas_nulos:\n",
    "        df = imputar_categoricas(df, columnas_categoricas_nulos)\n",
    "\n",
    "    # PASO 9: Imputaci√≥n de num√©ricas (si se especificaron columnas)\n",
    "    if columnas_numericas_nulos:\n",
    "        df = imputar_numericas(df, columnas_numericas_nulos)\n",
    "\n",
    "    if mostrar_resumen:\n",
    "        print(\"\\nüü¢ Limpieza general completada.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exportar_datos",
   "metadata": {},
   "source": [
    "---\n",
    "## **11. EXPORTACI√ìN DE DATOS LIMPIOS**\n",
    "\n",
    "Guardamos el DataFrame procesado para su uso en an√°lisis posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d331cad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Datos limpios exportados exitosamente a '../data/processed/hr_processed.csv'\n",
      "üìä Dimensiones finales del dataset: 1470 filas x 30 columnas\n"
     ]
    }
   ],
   "source": [
    "# Guardar el DataFrame limpio en la carpeta de datos procesados\n",
    "# Este archivo ser√° la fuente para an√°lisis exploratorio y modelado\n",
    "df.to_csv('../data/processed/hr_processed.csv')\n",
    "\n",
    "print(\"\\n‚úÖ Datos limpios exportados exitosamente a '../data/processed/hr_processed.csv'\")\n",
    "print(f\"üìä Dimensiones finales del dataset: {df.shape[0]} filas x {df.shape[1]} columnas\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
